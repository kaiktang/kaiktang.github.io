<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"kaiktang.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":{"disqus":{"text":"Load Disqus","order":-1}},"activeClass":"disqus"},"algolia":{"appID":"FBQ33HXA0Q","apiKey":"5a256d1a0d5075a6a17b29fbae8cdbdc","indexName":"blog","hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Hadoop的介绍 Hadoop是一个使用java编写的Apache开放源代码框架，它允许使用简单的编程模型跨大型计算机的大型数据集进行分布式处理。Hadoop框架工作的应用程序可以在跨计算机群集提供分布式存储和计算的环境中工作。Hadoop旨在从单一服务器扩展到数千台机器，每台机器都提供本地计算和存储。  Hadoop的架构 MapReduce：这是基于YARN的大型数据集并行处理系统。 YAR">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop学习（待续）">
<meta property="og:url" content="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/index.html">
<meta property="og:site_name" content="kaiktang&#39;s blogs">
<meta property="og:description" content="Hadoop的介绍 Hadoop是一个使用java编写的Apache开放源代码框架，它允许使用简单的编程模型跨大型计算机的大型数据集进行分布式处理。Hadoop框架工作的应用程序可以在跨计算机群集提供分布式存储和计算的环境中工作。Hadoop旨在从单一服务器扩展到数千台机器，每台机器都提供本地计算和存储。  Hadoop的架构 MapReduce：这是基于YARN的大型数据集并行处理系统。 YAR">
<meta property="og:locale">
<meta property="og:image" content="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/2017-12-15_11-09-39.png">
<meta property="og:image" content="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/2017-12-17_15-59-23.png">
<meta property="og:image" content="http://p0tsgngca.bkt.clouddn.com/yarn-structure.png">
<meta property="og:image" content="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/2017-12-20_21-35-01.png">
<meta property="article:published_time" content="2017-12-11T06:53:07.000Z">
<meta property="article:modified_time" content="2019-01-07T09:32:57.000Z">
<meta property="article:author" content="kaiktang">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/2017-12-15_11-09-39.png">

<link rel="canonical" href="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>Hadoop学习（待续） | kaiktang's blogs</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?8714a47efb513991b4862eafeadb6a3d";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">kaiktang's blogs</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="kaiktang">
      <meta itemprop="description" content="学而后知不足">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="kaiktang's blogs">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop学习（待续）
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2017-12-11 14:53:07" itemprop="dateCreated datePublished" datetime="2017-12-11T14:53:07+08:00">2017-12-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-01-07 17:32:57" itemprop="dateModified" datetime="2019-01-07T17:32:57+08:00">2019-01-07</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/12/11/Hadoop学习（待续）/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Hadoop的介绍"><a href="#Hadoop的介绍" class="headerlink" title="Hadoop的介绍"></a>Hadoop的介绍</h2><blockquote>
<p>Hadoop是一个使用java编写的Apache开放源代码框架，它允许使用简单的编程模型跨大型计算机的大型数据集进行分布式处理。Hadoop框架工作的应用程序可以在跨计算机群集提供分布式存储和计算的环境中工作。Hadoop旨在从单一服务器扩展到数千台机器，每台机器都提供本地计算和存储。</p>
</blockquote>
<h2 id="Hadoop的架构"><a href="#Hadoop的架构" class="headerlink" title="Hadoop的架构"></a>Hadoop的架构</h2><ul>
<li><strong>MapReduce</strong>：这是基于YARN的大型数据集并行处理系统。</li>
<li><strong>YARN</strong>：这是分布式作业调度和集群资源（主要是内存和CPU内核）管理的框架。</li>
<li><strong>HDFS</strong>：提供对应用程序数据的高吞吐量访问的分布式文件系统。能够存储海量数据，具有分布式、安全性（提供副本）等特点</li>
<li><strong>Common</strong>：这些是其他Hadoop模块所需的Java库和实用程序。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的必要Java文件和脚本。</li>
</ul>
<h2 id="Hadoop的运行模式"><a href="#Hadoop的运行模式" class="headerlink" title="Hadoop的运行模式"></a>Hadoop的运行模式</h2><ul>
<li>Local mode</li>
<li>Distributed Mode<ul>
<li>伪分布式<ul>
<li>一台机器，运行所有的守护进程</li>
</ul>
</li>
<li>完全分布式<ul>
<li>有多个从节点</li>
<li>配置文件 slaves</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="完全分布式下的配置"><a href="#完全分布式下的配置" class="headerlink" title="完全分布式下的配置"></a>完全分布式下的配置</h3><ul>
<li><p>hdfs</p>
<ul>
<li>hadoop-env.sh</li>
</ul>
<blockquote>
<p>配置java环境变量</p>
</blockquote>
<ul>
<li>core-site.xml</li>
</ul>
<blockquote>
<ul>
<li><code>fs.defaultFS</code>配置NameNode的地址</li>
<li><code>hadoop.tmp.dir</code>配置Hadoop临时目录</li>
<li><code>fs.trash.interval</code>垃圾回收周期</li>
</ul>
</blockquote>
<ul>
<li>hdfs-site.xml</li>
</ul>
<blockquote>
<ul>
<li><code>dfs.replication</code>配置副本数</li>
<li><code>dfs.namenode.secondary.http-address</code>配置secondary namenode的地址</li>
<li><code>dfs.datanode.data.dir</code>设置DataNode实际存放数据的目录</li>
</ul>
</blockquote>
<ul>
<li>slaves</li>
</ul>
<blockquote>
<p>配置DataNode和NodeManager</p>
</blockquote>
</li>
<li><p>yarn</p>
<ul>
<li>yarn-env.sh</li>
</ul>
<blockquote>
<p>配置java环境变量</p>
</blockquote>
<ul>
<li>yarn-site.xml</li>
</ul>
<blockquote>
<ul>
<li><code>yarn.resourcemanager.hostname</code>配置resource manager的位置</li>
<li><code>yarn.nodemanager.resource.memory-mb</code>配置NodeManager资源</li>
<li><code>yarn.log-aggregation-enable</code>配置日志聚合</li>
<li><code>yarn.log-aggregation.retain-seconds</code>配置日志保存时间​</li>
</ul>
</blockquote>
<ul>
<li>slaves</li>
</ul>
</li>
<li><p>mapreduce</p>
<ul>
<li>mapred-env.sh</li>
<li>mapred-site.xml</li>
</ul>
</li>
<li><p>通过ntp来进行集群的时间同步</p>
<blockquote>
<ul>
<li>服务器编辑：/etc/ntp.conf</li>
<li>服务器编辑：/etc/sysconfig/ntpd  SYNC_HWCLOCK=yes</li>
<li>客户端每十分钟校正：<ul>
<li><code>crontable -e</code></li>
<li><code>0-59/10 * * * * /user/sbin/ntpdate SERVER_HOST_NAME</code></li>
</ul>
</li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="Hadoop生态"><a href="#Hadoop生态" class="headerlink" title="Hadoop生态"></a>Hadoop生态</h2><ul>
<li><strong>sqoop</strong>：SQL to Hadoop，即将关系型数据库如Oracle、Mysql等的数据导入到HDFS中<ul>
<li>Map读数据，Reduce写数据</li>
</ul>
</li>
<li><strong>Cloudera Manager</strong>：方便部署安装集群、监控集群、配置同步集群、预警等等</li>
<li><strong>Zoo Keeper</strong>：开源的基于观察者模式的分布式框架，为分布式应用提供协调服务的Apache项目</li>
</ul>
<h2 id="各个监控界面"><a href="#各个监控界面" class="headerlink" title="各个监控界面"></a>各个监控界面</h2><ul>
<li><a target="_blank" rel="noopener" href="http://localhost-centos:50070/">HDFS信息监控</a></li>
<li><a target="_blank" rel="noopener" href="http://localhost-centos:8088/">YARN信息监控</a></li>
<li><a target="_blank" rel="noopener" href="http://localhost-centos:19888/">任务历史信息监控</a></li>
</ul>
<h2 id="Hadoop-HDFS"><a href="#Hadoop-HDFS" class="headerlink" title="Hadoop HDFS"></a>Hadoop HDFS</h2><p>采用主/从架构，包含一个主节点（<em>NameNode</em>）和若干个从节点（<em>DataNode</em>）还有<em>Secondary NameNode</em>。在其上的文件采用分块存储，每个block默认68MB。</p>
<h3 id="主节点：NameNode"><a href="#主节点：NameNode" class="headerlink" title="主节点：NameNode"></a>主节点：NameNode</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>用于存储文件的元数据，如文件名、文件目录结构、文件属性（生成时间，副本数，文件权限）以及每个文件的块列表和块所在的<em>DataNode</em>信息。其中元信息存放在内存中，加快访问。在<em>NameNode</em>的本地磁盘上存放着<strong>fsimage</strong>（镜像文件）和<strong>edites</strong>（编辑日志）。</p>
<ul>
<li><em>NameNode</em>是一个中心服务器，单一节点（简化系统的设计和实现），负责管理文件系统的命名空间（namespace）以及客户端对文件的访问。</li>
<li>文件操作：<em>NameNode</em>负责文件元数据如文件名、文件目录结构、文件属性（生成时间，副本数，文件权限）以及每个文件的块列表和块所在的<em>DataNode</em>信息的操作，<em>DataNode</em>负责处理文件内容的读写请求，跟文件内容相关的数据流不经过NameNode，只会询问它跟那个<em>DataNode</em>的联系，不然<em>NameNode</em>会成为系统的瓶颈</li>
<li>副本存放在哪些<em>DataNode</em>上由NameNode来控制，根据全局情况作出块放置决定，读取文件时<em>NameNode</em>尽量让用户先读取最近的副本，降低块消耗和读取延时。</li>
<li>NameNode全权管理数据库的复制，它周期性地从集群中每个DataNode接收心跳信号和块状态报告（Blockreport）。接收到心跳信号意味着该DataNode工作正常。块状态报告包含了一个改DataNode上所有数据块的列表。<u>所以在集群配置的时候，当NameNode中显示某一个机子在运行的DataNode没有启动，可能是因为“心跳”没有被接收到，可能他们不在同一个网段。</u></li>
</ul>
<h4 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h4><p>在NameNode的启动过程中，会有个一个安全模式</p>
<ul>
<li><p>安全模式下，NameNode会等待DataNodes向它汇报block report</p>
</li>
<li><p>然后计算DataNodes blocks / total blocks，当这个比率超过99.9%之后，安全模式就会关闭</p>
</li>
<li><p>在安全模式下：</p>
<ul>
<li>只能进行读取操作</li>
<li>不能进行其他修改操作</li>
</ul>
</li>
<li><p>这种自动开启的安全模式，会自动关闭，而手动开启的需要手动关闭。</p>
</li>
<li><p>手动开启安全模式：  <code>bin/hdfs dsadmin -safemode enter</code></p>
<p>​</p>
<p>​</p>
</li>
</ul>
<h3 id="从节点：DataNode"><a href="#从节点：DataNode" class="headerlink" title="从节点：DataNode"></a>从节点：DataNode</h3><p>实际存储文件block的地方（还有块数据的校验和）。</p>
<ul>
<li>一个数据块在DataNode以文件存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳</li>
<li>心跳每3秒一次，心跳返回结果带有NameNode给该DataNode的命令，如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。</li>
<li>集群运行中可以安全加入和退出一些机器。当一个DataNode离线后，NameNode会调用其他DataNode来恢复出丢失的数据。</li>
</ul>
<p>我们配置的Hadoop的临时目录，里面有dfs、mapred、nm-local-dir三个目录，其中dfs中是DataNode中实际存放数据的地方。</p>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><p>用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p>
<h3 id="HDFS的启动过程"><a href="#HDFS的启动过程" class="headerlink" title="HDFS的启动过程"></a>HDFS的启动过程</h3><ul>
<li>第一次启动HDFS集群<ol>
<li>格式化HDFS文件系统</li>
<li>生成fsimage</li>
<li>启动NameNode</li>
<li>读取fsimage</li>
<li>开启DataNode</li>
<li>DataNode向NameNode注册，并且定期向NameNode发送block report</li>
<li>用户操作HDFS文件系统，增删改查</li>
<li>NameNode将操作记录存放在磁盘上的edits中</li>
</ol>
</li>
<li>第n次启动HDFS集群<ol>
<li>启动NameNode</li>
<li>读取fsimage</li>
<li>读取edits（操作记录）</li>
<li>生成一个新的fsimage + 一个空的edits</li>
<li>启动DataNode</li>
<li>用户操作HDFS文件系统</li>
<li>操作记录写入edits</li>
<li>…</li>
</ol>
</li>
</ul>
<p>可以想象如果只是单纯的这种模式的话，那么如果整个集群长时间不重启，edits文件将会非常大，那么下一次重启合并的时间将会非常长，而解决这个问题的方案就是Secondary NameNode。即定期将fsimage和edits合并，并生成新的fsimage并且生成空的edits，周期大约1小时。</p>
<h3 id="HDFS-HA-using-QJM"><a href="#HDFS-HA-using-QJM" class="headerlink" title="HDFS HA using QJM"></a>HDFS HA using QJM</h3><ul>
<li>NameNode Active<ul>
<li>向JournalNode写edits文件，超过半数写成功即可保证正确</li>
</ul>
</li>
<li>NameNode Standby<ul>
<li>向JournalNode读edits文件，以此来保证两个NN的同步</li>
<li>接收所有DataNode的报告</li>
</ul>
</li>
<li>配置要点<ul>
<li>共享edits（通过JournalNode，至少3个，为奇数）</li>
<li>NameNode（Active，Standby）</li>
<li>Client（Proxy）</li>
<li>fence（隔离，保证同一时刻只有一个NN对外提供服务）</li>
<li>使用Zookeeper进行自动故障转移（failover）</li>
</ul>
</li>
</ul>
<p><img src="2017-12-15_11-09-39.png" alt="Hadoop HA"></p>
<p><img src="2017-12-17_15-59-23.png" alt="自动故障转移"></p>
<h3 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h3><p>让不同的NameNode去保存不同应用的元数据，但是共用DataNodes</p>
<h3 id="Distributed-copy"><a href="#Distributed-copy" class="headerlink" title="Distributed copy"></a>Distributed copy</h3><p>集群数据迁移</p>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p>每个从节点有一个NodeManager来管理该节点的资源，集群资源通过ResourceManager来管理。</p>
<h3 id="主要组件"><a href="#主要组件" class="headerlink" title="主要组件"></a>主要组件</h3><ul>
<li>ResourceManager<ul>
<li>处理客户端请求</li>
<li>启动/监控Application Master</li>
<li>监控NodeManager</li>
<li>资源分配与调度</li>
</ul>
</li>
<li>NodeManager<ul>
<li>单个节点上的资源管理</li>
<li>处理来自ResourceManager的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ul>
</li>
<li>ApplicationMaster<ul>
<li>数据切分</li>
<li>为应用程序申请资源，并分配给内部任务</li>
<li>任务监控与容错</li>
</ul>
</li>
<li>Container</li>
<li>对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息</li>
</ul>
<h3 id="YARN上运行应用"><a href="#YARN上运行应用" class="headerlink" title="YARN上运行应用"></a>YARN上运行应用</h3><p><img src="http://p0tsgngca.bkt.clouddn.com/yarn-structure.png" alt="yarn上运行应用"></p>
<ol>
<li>应用提交给ResourceManager</li>
<li>ResourceManager在一个DataNode上为一个应用（如MapReduce）创建Container（其中一个Container中运行Application Master）</li>
<li>App Master进行任务划分，去找ResourceManager的ApplicationManager中注册</li>
<li>去找ResourceManager的去ResourceScheduler申请资源</li>
<li>App Master去各个NodeManager要求启动任务</li>
<li>NodeManager为任务开辟Container运行任务</li>
<li>每个任务向App Master汇报任务的状态</li>
<li>应用解决，App Master包裹ResourceManager任务结束，之后结束退出</li>
</ol>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><h3 id="MapReduce任务八股文"><a href="#MapReduce任务八股文" class="headerlink" title="MapReduce任务八股文"></a>MapReduce任务八股文</h3><details><br>​    <summary>以WordCount为例</summary><br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configured;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.Tool;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ToolRunner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@ClassName</span>: WordCount</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 字符统计map reduce任务</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: tomkk</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>: 2017-12-07</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> <span class="keyword">extends</span> <span class="title class_">Configured</span> <span class="keyword">implements</span> <span class="title class_">Tool</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">run</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(getConf(), WordCount.class.getSimpleName());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. set run as jar</span></span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. set input</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">inPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]);</span><br><span class="line">        FileInputFormat.addInputPath(job, inPath);</span><br><span class="line">        <span class="comment">//set TextInputFormat to format input file to key-value</span></span><br><span class="line">        job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. set map</span></span><br><span class="line">        job.setMapperClass(wcMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6. set reduce</span></span><br><span class="line">        job.setReducerClass(wcReducer.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//7. set output</span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">outPath</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]);</span><br><span class="line">        FileOutputFormat.setOutputPath(job, outPath);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//8. submit job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">status</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">return</span> status ? <span class="number">0</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * WordCount Map类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">wcMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">mapOutputKey</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">mapOutputValue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;key = &quot;</span> + key);</span><br><span class="line">            System.out.println(<span class="string">&quot;value = &quot;</span> + value);</span><br><span class="line"></span><br><span class="line">            <span class="type">StringTokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringTokenizer</span>(value.toString(), <span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> (tokenizer.hasMoreElements()) &#123;</span><br><span class="line">                mapOutputKey.set(tokenizer.nextToken());</span><br><span class="line"></span><br><span class="line">                context.write(mapOutputKey, mapOutputValue);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="comment">//NOTHING</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="comment">//NOTHING</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * WordCount Reduce类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">wcReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">reduceOutputValue</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">                sum += value.get();</span><br><span class="line">            &#125;</span><br><span class="line">            reduceOutputValue.set(sum);</span><br><span class="line">            context.write(key, reduceOutputValue);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="comment">//NOTHING</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">            <span class="comment">//NOTHING</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (args.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;参数过少&quot;</span>);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//1. get configuration</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ToolRunner.run(configuration, <span class="keyword">new</span> <span class="title class_">WordCount</span>(), args);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><br></details>

<h3 id="MapReduce的执行过程"><a href="#MapReduce的执行过程" class="headerlink" title="MapReduce的执行过程"></a>MapReduce的执行过程</h3><blockquote>
<p>参考1：<a target="_blank" rel="noopener" href="http://www.cnblogs.com/sunddenly/p/3985386.html">Hadoop日记Day12—MapReduce学习</a></p>
<p>参考2：<a target="_blank" rel="noopener" href="http://www.cnblogs.com/npumenglei/p/3631244.html">MapReduce 过程详解 - 雷子-晓飞爸 - 博客园</a></p>
</blockquote>
<p>在shuffle过程中可以自定义的过程有</p>
<ul>
<li><p>partition：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPartitionerClass</span><span class="params">(Class&lt;? extends Partitioner&gt; cls)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>combine：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setCombinerClass</span><span class="params">(Class&lt;? extends Reducer&gt; cls)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>sort：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSortComparatorClass</span><span class="params">(Class&lt;? extends RawComparator&gt; cls)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>group：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setGroupingComparatorClass</span><span class="params">(Class&lt;? extends RawComparator&gt; cls)</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>压缩：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">configuration.set(<span class="string">&quot;mapreduce.map.output.compress&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">configuration.set(<span class="string">&quot;mapreduce.map.output.compress.codec&quot;</span>, <span class="string">&quot;org.apache.hadoop.io.compress.SnappyCodec&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="MapReduce数据类型"><a href="#MapReduce数据类型" class="headerlink" title="MapReduce数据类型"></a>MapReduce数据类型</h3><p>特殊的有：</p>
<p>​    NullWritable：当&lt;key, value&gt;中的key或value为空时使用</p>
<p>​    Text：使用UTF-8格式存储文本</p>
<h3 id="MapReduce调优"><a href="#MapReduce调优" class="headerlink" title="MapReduce调优"></a>MapReduce调优</h3><ol>
<li><p>Reduce Task Number：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//java代码中针对某个任务配置</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setNumReduceTasks</span><span class="params">(<span class="type">int</span> tasks)</span>; <span class="comment">//默认为1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//配置文件中</span></span><br><span class="line">mapreduce.job.reduces=<span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Map Task输出压缩</p>
<ol>
<li>bzip2：最节省存储空间</li>
<li>gzip</li>
<li>lzo：解压速度最快</li>
<li>snappy<br>压缩比：bzip2 &gt; gzip &gt; lzo<br>解压速度：lzo &gt; gzip &gt; bzip2</li>
</ol>
<p>效果：</p>
<ol>
<li>map阶段写到磁盘IO减少</li>
<li>reduce阶段，读取磁盘信息的网络IO减少</li>
</ol>
<p><img src="2017-12-20_21-35-01.png" alt="数据压缩"></p>
</li>
<li><p>Shuffle Phase参数</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#The number of streams to merge at once while sorting files. This determines the number of open file handles.</span><br><span class="line">mapreduce.task.io.sort.factor=10</span><br><span class="line"></span><br><span class="line">#The total amount of buffer memory to use while sorting files, in megabytes. By default, gives each merge stream 1MB, which should minimize seeks.</span><br><span class="line">mapreduce.task.io.sort.mb=100</span><br><span class="line"></span><br><span class="line">#The soft limit in the serialization buffer. Once reached, a thread will begin to spill the contents to disk in the background. Note that collection will not block if this threshold is exceeded while a spill is already in progress, so spills may be larger than this threshold when it is set to less than .5</span><br><span class="line">mapreduce.map.sort.spill.percent=0.80</span><br><span class="line"></span><br><span class="line">#The number of virtual cores to request from the scheduler for each map task.</span><br><span class="line">mapreduce.map.cpu.vcores=1</span><br><span class="line"></span><br><span class="line">#The amount of memory to request from the scheduler for each reduce task.</span><br><span class="line">mapreduce.reduce.cpu.vcores=1</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>参考：<a target="_blank" rel="noopener" href="http://blog.javachen.com/2014/06/24/tuning-in-mapreduce.html">MapReduce任务参数调优</a></p>
</blockquote>
<hr>
<p>所有的数据类型都实现了<strong>Writable</strong>接口，其中有<strong>write</strong>和<strong>readFilelds</strong>两个方法，用于序列化和反序列化，需要注意write和read的顺序相对应。还实现了<strong>WritableComparable</strong>接口，其继承了<strong>Comparable</strong>接口，因为在Map阶段会有根据key值sort的过程。</p>
<p>​    所以如果需要自定义key的类型的话，需要继承<strong>WritableComparable</strong>接口，value则不用。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="kaiktang WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="kaiktang Alipay">
        <p>Alipay</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/12/10/hello-world/" rel="prev" title="Hello World">
      <i class="fa fa-chevron-left"></i> Hello World
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/12/13/%E6%95%B4%E5%90%88spring-boot%E3%80%81spring-mvc%E3%80%81mybatis%E5%AE%9E%E8%B7%B5/" rel="next" title="整合spring boot、spring mvc、mybatis实践">
      整合spring boot、spring mvc、mybatis实践 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.</span> <span class="nav-text">Hadoop的介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%9A%84%E6%9E%B6%E6%9E%84"><span class="nav-number">2.</span> <span class="nav-text">Hadoop的架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%9A%84%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.</span> <span class="nav-text">Hadoop的运行模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8B%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="nav-number">3.1.</span> <span class="nav-text">完全分布式下的配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E7%94%9F%E6%80%81"><span class="nav-number">4.</span> <span class="nav-text">Hadoop生态</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%84%E4%B8%AA%E7%9B%91%E6%8E%A7%E7%95%8C%E9%9D%A2"><span class="nav-number">5.</span> <span class="nav-text">各个监控界面</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop-HDFS"><span class="nav-number">6.</span> <span class="nav-text">Hadoop HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%8A%82%E7%82%B9%EF%BC%9ANameNode"><span class="nav-number">6.1.</span> <span class="nav-text">主节点：NameNode</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">6.1.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="nav-number">6.1.2.</span> <span class="nav-text">安全模式</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%8E%E8%8A%82%E7%82%B9%EF%BC%9ADataNode"><span class="nav-number">6.2.</span> <span class="nav-text">从节点：DataNode</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Secondary-NameNode"><span class="nav-number">6.3.</span> <span class="nav-text">Secondary NameNode</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS%E7%9A%84%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B"><span class="nav-number">6.4.</span> <span class="nav-text">HDFS的启动过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-HA-using-QJM"><span class="nav-number">6.5.</span> <span class="nav-text">HDFS HA using QJM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HDFS-Federation"><span class="nav-number">6.6.</span> <span class="nav-text">HDFS Federation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distributed-copy"><span class="nav-number">6.7.</span> <span class="nav-text">Distributed copy</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YARN"><span class="nav-number">7.</span> <span class="nav-text">YARN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E7%BB%84%E4%BB%B6"><span class="nav-number">7.1.</span> <span class="nav-text">主要组件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#YARN%E4%B8%8A%E8%BF%90%E8%A1%8C%E5%BA%94%E7%94%A8"><span class="nav-number">7.2.</span> <span class="nav-text">YARN上运行应用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce"><span class="nav-number">8.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E4%BB%BB%E5%8A%A1%E5%85%AB%E8%82%A1%E6%96%87"><span class="nav-number">8.1.</span> <span class="nav-text">MapReduce任务八股文</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B"><span class="nav-number">8.2.</span> <span class="nav-text">MapReduce的执行过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">8.3.</span> <span class="nav-text">MapReduce数据类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce%E8%B0%83%E4%BC%98"><span class="nav-number">8.4.</span> <span class="nav-text">MapReduce调优</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="kaiktang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">kaiktang</p>
  <div class="site-description" itemprop="description">学而后知不足</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:tomkklalala@qq.com" title="E-Mail → mailto:tomkklalala@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">kaiktang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://kaiktang.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://kaiktang.github.io/2017/12/11/Hadoop%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%BE%85%E7%BB%AD%EF%BC%89/";
    this.page.identifier = "2017/12/11/Hadoop学习（待续）/";
    this.page.title = "Hadoop学习（待续）";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://kaiktang.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
